[
  {
    "path": "posts/2021-11-29-eds-222-final-blog/",
    "title": "Are California Wildfires Getting more Intense in the North or South?",
    "description": "EDS 222 Final Project: Exploring geographic trends of wildfire intensity in California over time",
    "author": [
      {
        "name": "Felicia Cruz",
        "url": {}
      }
    ],
    "date": "2021-11-29",
    "categories": [
      "MEDS",
      "Statistics"
    ],
    "contents": "\n\nContents\nMotivate the question / Introduction\nData Description\nAnalysis Plan\nResults\nFurther Analysis\nReferences\n\n\n\nShow code\n\n# basic data set up and wrangling \n\n# read in dataset from Kaggle \nfires <- read_csv(here(\"_posts/2021-11-29-eds-222-final-blog/California_Fire_Incidents.csv\")) %>% \n  clean_names()\n\n# make a year_started column \nfires$started <- lubridate::as_date(fires$started)\nfires <- fires %>% \n  mutate(started_year = lubridate::year(started))\n\n# remove 1969 start years \nfires <- fires %>% \n  filter(started_year != 1969)\n\n# subset for variables of interest \nfires_sub <- fires %>% \n  select(acres_burned, archive_year, counties, extinguished, latitude, location, longitude, name, started, unique_id, started_year)\n\n# add north_south\n# establish locations North and South \n\nfires_sub$north_south <- 0\n \n# want 0 if North and 1 for South \nfires_sub$north_south <- replace(fires_sub$north_south,\n                             fires_sub$latitude > 36,\n                             \"North\")\nfires_sub$north_south <- replace(fires_sub$north_south,\n                             fires_sub$north_south == 0,\n                             \"South\")\n\n\n\n\n\nShow code\n\n# time series of all events \n\nts <- ggplot(fires, aes(x = started, y = acres_burned)) +\n  geom_line() + \n    labs(title = \"Wildfire Events in California (2013-2019)\",\n       x = \"Start Date\",\n       y = \"Acres Burned\")\n\n\n\nMotivate the question / Introduction\nGrowing up in the Antelope Valley, located in the Mojave Desert at the northern edge of LA County, I experienced wildfires at a very young age. As I grew up, orange haze outside, flying ash, and evacuation announcements on the news were not out of the ordinary during the later summer months. I will never forget taking a day trip to the beach with my family one summer only to come home to barricades outside our neighborhood because a wildfire had jumped the nearby ridge deeming it unsafe to enter. While our house, and my dog inside, was thankfully intact, we were reminded of the event for months by the charred hill next to our house.\nThe statistics describing the frequency, intensity, and destructiveness of California wildfires are alarming to say the least, and are all likely to be further exacerbated by the climate crisis in the years to come. As temperature and droughts increase with elevated greenhouse gas emissions, it is probable that we can expect more wildfires in the future, especially with the fire seasons getting longer.\nIn the past couple decades, California’s wildfire season has progressively gotten worse. In recent years especially, fires seem to be getting both more intense and more frequent. For example, the 2017 season was the most destructive wildfire season on record at the time, with 1.2 million acres burned. The largest fire during that season was the Thomas Fire in Santa Barbara County, which was California’s largest modern wildfire at the time. In 2020, 4.2 million acres were burned, amounting to more than 4% of the state’s total land. This resulted in 2020 being the largest wildfire season recorded in California’s modern history. The August 2020 Complex Fire alone burned more than 1 million acres, making it the first “gigafire” on record.\n\n\nShow code\n\n# total acres burned by year and region \n\nacres_by_region <- fires_sub %>% \n  group_by(started_year, north_south) %>% \n  summarize(total_acres = sum(acres_burned, na.rm = TRUE))\n\ntotal_acres <- ggplot(acres_by_region, aes(x = started_year, y = total_acres,\n                                           color = north_south)) +\n  geom_line() +\n  labs(title = \"Total Acres Burned by Year\",\n       color = \"\",\n       x = \"Year\",\n       y = \"Acres\")\n\ntotal_acres\n\n\n\n\nFigure 1: Total Acres Burned (2013-2019)\n\n\n\nEach year, I hear and read about wildfires all over California. Just this year, I remember talking with some friends about hazy air quality in Santa Barbara. We were wondering if it was due to smoke from fires in the north or the south because there were many wildfires burning at the time.\nI am interested in how California wildfires have changed over time, and if this change is different in the north than in the south. Are California wildfires getting more intense in the northern part of the state or in the south? Is there a difference in trends between start date and acres burned for fires in the north versus fires in the South?\nFrom my preliminary research, there does not seem to be existing evidence on this question. While many articles discuss factors that contribute to the growing wildfires in California, there is not much to be said about how geographic location is potentially correlated with changes in wildfires over time.\nData Description\nTo explore changes in California’s wildfire season and compare trends in the North to the South, I will be using a dataset which contains over 1600 wildfire events in the state between 2013 and 2020. This dataset is made available on Kaggle.com and was originally scraped from records on the CAL FIRE website. For each fire, this dataset contains 40 variables; for the purposes of this analysis, the most relevant variables include latitude and longitude, start date, extinguished date, and acres burned. A potential limitation of this dataset is that it only includes wildfires responded to by CAL FIRE; many wildfire events that contribute to the overall trends in the north and the south may not be included in this dataset.\nAnalysis Plan\nTo assess the effects of wildfire start date and location on the number of acres burned, I will be using the following interaction model:\n\\[acres\\_burned_i=\\beta_{0}+\\beta_{1} \\cdot started_i + \\beta_{2} \\cdot north\\_south_i + \\beta_{3} \\cdot started_i \\cdot north\\_south_i + \\varepsilon_i\\] The variable north_south takes on a value of “North” for all wildfires occurring above 36 degrees latitude, and everything below this is assigned “South”. I have chosen this interaction model in order to see if wildfire trends differ in the north and south.\nAfter running this regression, I will determine if the slope coefficients are statistically significant by looking at the associated p-values.\nResults\nFrom the regression output in Table 1, we can see that the intercept for fires that occur in the South is 24,345 acres above the intercept for fires in the South. The slope of the regression line for fires in the South has a slope that is 1.56 less than that of the regression line for fires in the North. In other words, the trend line for northern fires is steeper.\n\n\nShow code\n\nmod <- lm(acres_burned ~ started + north_south + started*north_south, data = fires_sub)\n\nmod_summary <- mod %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Multiple Linear Regression Output\",\n        digits = 2) %>% \n  kable_styling(latex_options = \"HOLD_position\")\n\nmod_summary\n\n\n\nTable 1: Multiple Linear Regression Output\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n-21405.07\n\n\n22705.70\n\n\n-0.94\n\n\n0.35\n\n\nstarted\n\n\n1.57\n\n\n1.31\n\n\n1.19\n\n\n0.23\n\n\nnorth_southSouth\n\n\n24344.65\n\n\n34590.61\n\n\n0.70\n\n\n0.48\n\n\nstarted:north_southSouth\n\n\n-1.56\n\n\n2.01\n\n\n-0.78\n\n\n0.44\n\n\nWhile this model does show a difference in slopes, because the p-values are so high, these results are not statistically significant. We do not have sound evidence that there is a difference in wildfire intensity over time between the North and South. This brief analysis does not help to answer the original question. More data would be needed to perform a more robust and comprehensive analysis to accurately answer the question “Are California wildfires getting more intense in the northern part of the state or in the south?”\n\n\nShow code\n\nggplot(data = fires_sub, aes(x = started, y = acres_burned, color = north_south)) +\n  geom_point(alpha = 0.4) +\n  geom_line(data = augment(mod), aes(y = .fitted, color = north_south)) +\n  labs(title = \"\",\n       x = \"Start Date\",\n       y = \"Acres Burned\",\n       color = \"\") +\n  theme(plot.caption.position = \"plot\",\n        plot.caption = element_text(hjust = 0))\n\n\n\n\nFigure 2: Acres Burned vs. Start Date\n\n\n\nFurther Analysis\nmore years of fire data\n7 years is not enough for a robust analysis of the question posed\n2020 fire season is not included\ntime series analysis/predictions\nIn order to accurately answer this question, much more data is needed. This dataset only includes wildfire events during a seven year span. To get a more thorough picture of the trends in acres burned for northern and southern wildfires in California over time, a much larger temporal range is needed beyond the 7 years provided in this dataset. Additionally, this dataset does not include 2020 data which means observations from the largest fire season on record are not taken into account in this preliminary analysis. With more data points spanning a 20-30 year period, I suspect much more interesting and informative results.\nBeyond doing a regression analysis to explore differences in geographic trends in wildfire intensity over time, doing time series analyses to produce predictions of wildfire intensity would also be useful. This type of analysis would be of interest to government organizations, first responders in California, and the general public living in fire-prone areas of California.\nLastly, looking at seasonal trends over time can help identify if and how the wildfire season itself is changing. This type of analysis could help answer questions such as: Is the wildfire season in California getting longer? Are more intense wildfires happening at a certain point in the season?\nReferences\nhttps://www.fire.ca.gov/incidents/2018/ https://www.fire.ca.gov/incidents/2020/ https://www.latimes.com/california/story/2020-10-01/northern-california-fire-season-less-rain-than-southern-california http://resp.llas.ac.cn/C666/handle/2XK7JSWQ/323227\n\n\n\n",
    "preview": "posts/2021-11-29-eds-222-final-blog/2021-fire-map.png",
    "last_modified": "2021-11-30T16:18:01-08:00",
    "input_file": "eds-222-final-blog.knit.md",
    "preview_width": 920,
    "preview_height": 824
  },
  {
    "path": "posts/2021-10-20-data-retrieval/",
    "title": "Using an API to Programmatically Access and Download Data",
    "description": "Using the `dataRetrieval` package to analyze USGS datasets",
    "author": [
      {
        "name": "Felicia Cruz",
        "url": {}
      }
    ],
    "date": "2021-11-02",
    "categories": [
      "packages",
      "MEDS"
    ],
    "contents": "\n\nContents\nTime Series for 2021\nMontecito Mudslides: January 9, 2018\nTakeaways\n\nDuring my EDS 213 course titled “Metadata Standards, Data Modeling and Data Semantics” I learned how to use an API to programmatically retrieve data.\nUsing the dataRetrieval package to access USGS water gauge data, I will be looking at the Ventura River and Santa Paula Creek gauges to explore rain events and patterns.\nTime Series for 2021\n\n\nShow code\n\n# Query both sites at once by passing in a vector for the siteNumber argument  \n# Ventura is 1111850\n# Santa Paula is 1111350\n\n# subset for just 2021 \ncombined <- readNWISdv(siteNumber = c(\"11118500\", \"11113500\"),\n                       parameterCd = \"00060\",\n                       startDate = \"2021-01-01\",\n                       endDate = \"2021-11-01\") \n\n# rename the discharge column and drop the unnecessary variables \ncombined$discharge <- combined$X_00060_00003\ncombined <- combined %>% \n  select(site_no, Date, discharge) %>% \n  mutate(site_no = case_when(site_no == \"11118500\" ~ \"Ventura\",\n            TRUE ~ \"Santa Paula\"))\n\n\n\nOne of my favorite things about living in the Santa Barbara area is the beautiful weather. With sunny skies and warm temperatures most days, I have become quite sensitive to even small drops in temperature or brief rain episodes. In 2021, we have experienced very little rain thus far. From the plot below, we can see that the highest level of water discharge for either site was less than 15 cubic feet per second. Besides this spike, levels were consistently under 5 cubic feet per second.\n\n\nShow code\n\n# make a time series plot with both sites \n\nggplot(data = combined, aes(x = Date, y = discharge)) +\n  geom_line(aes(color = site_no)) +\n  ylim(0, 15) +\n  labs(title = \"Water Discharge, Santa Paula and Ventura\",\n       subtitle = \"2021-01-01 - 2021-11-01\",\n       color = \"Site\",\n       y = \"Discharge (cubic ft/s)\")\n\n\n\n\nMontecito Mudslides: January 9, 2018\nThe Thomas Fire in December of 2018 ended my first quarter of college early and postponed my first finals week. Once the fire was contained after the holidays, I thought I would be returning to a somewhat normal college experience…until the Montecito Mudslides happened.\nJust as the Thomas Fire was nearing complete containment, heavy rainfall on January 9, 2019 washed away massive amounts of mud and debris loosened from the areas burned by the fire. These mudslides sadly resulted in 23 deaths and the destruction of around 100 residences. After a quick weekend trip home in January, the Highway 101 closure due to these mudslides meant in order to get back to school I needed to take a short boat trip from Ventura Harbor to Santa Barbara.\nIn the time series plot above, I used the readNWISdv to retrieve daily values of water discharge. By using the readNWISuv function, I can download data that includes readings for every 15 minutes on a given day. Filtering for January 9, 2018, I can look at the frequency and intensity of rainfall for this particular day.\n\n\nShow code\n\n# getting instantaneous data for January 9 to look at water discharge \n\ncombined_jan_9_18 <- readNWISuv(siteNumbers =  c(\"11118500\", \"11113500\"),\n                       parameterCd = \"00060\",\n                       startDate = \"2018-01-09\",\n                       endDate = \"2018-01-09\",\n                       tz = \"America/Los_Angeles\")\n\ncombined_jan_9_18$discharge <- combined_jan_9_18$X_00060_00000\n\ncombined_jan_9_18 <- combined_jan_9_18 %>% \n  select(site_no, dateTime, discharge) %>% \n  mutate(site_no = case_when(site_no == \"11118500\" ~ \"Ventura\",\n            TRUE ~ \"Santa Paula\"))\n\nggplot(combined_jan_9_18, aes(x = dateTime, y = discharge)) +\n  geom_line(aes(color = site_no)) +\n  labs(y = \"Discharge (cubic ft/s)\",\n       color = \"Site\",\n       title = \"Water Discharge\",\n       subtitle = \"2018-01-09\",\n       x = \"Time\") \n\n\n\n\nFrom the above plot, we can see that water discharge peaked at around 6000 cubic feet per second at about 7 am on January 9. Compared to the maximum discharge in 2021 so far of 15 cubic feet per second, this highlights the intensity of the rainfall that triggered the Montecito Mudslides back in 2018. In a place of such low rainfall like Santa Barbara County, it is unlikely that such a massive rain event would occur and bring with it such devastating consequences, but the burn scars left by the Thomas Fire made these mudslides practically inevitable.\nTakeaways\nUsing an API to access and download data was extremely simple and fast. Instead of taking the time to download massive csv files off the internet to then use in an R script, using a package like dataRetrieval (or metajam which is used to access DataONE datasets) streamlines this process. It also makes it quick and easy to edit your code in case your dates or regions of interest change, as opposed to going back to the website to download another couple csv files.\n\n\n\n",
    "preview": "posts/2021-10-20-data-retrieval/images/dataretrieval_hex.png.crdownload",
    "last_modified": "2021-11-29T22:31:41-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-16-aug-16/",
    "title": "Two weeks as a MEDS student",
    "description": "A few functions I learned and key takeaways from my first two weeks in MEDS",
    "author": [
      {
        "name": "Felicia Cruz",
        "url": {}
      }
    ],
    "date": "2021-08-16",
    "categories": [
      "packages",
      "MEDS"
    ],
    "contents": "\nSome functions I have found particularly useful are group_by() and summarize(). Working together, these two functions will recognize groups that are specified in the arguments and then compute chosen summary statistics represented in a new data frame.\nHere is an example of how these functions can be used to find the mean flipper length for each penguin species in the palmerpenguins dataset.\n\n\nflipper_length_by_species <- penguins %>%\n  group_by(species) %>% \n  summarize(mean_flipper_length = mean(flipper_length_mm, na.rm = TRUE))\n\n\n\n\n# A tibble: 3 × 2\n  species   mean_flipper_length\n  <fct>                   <dbl>\n1 Adelie                   190.\n2 Chinstrap                196.\n3 Gentoo                   217.\n\nJust by using these two functions, from the new data frame we can quickly see that Gentoos have the longest flipper length on average.\nBeyond just learning useful functions, I have also deepened my understanding of tidy data. While I used to think that “tidy data” simply referred to datasets that were visually clean and organized, I have come to learn that tidy data refers to data that follows a certain structure. The three criteria that must be met for data to be considered “tidy” are:\nEach variable must be a column\nEach observation must be a row\nEach cell can contain only one value\nWhen data is in tidy form, this allows for easier visualizations and analyses.\nLastly, a key takeaway I have learned in my first two weeks as a data science student is that collaboration is critical. Whether collaboration means testing functions together or simply spotting an unmatched parentheses, I have really enjoyed the teammwork aspect that comes along with working in this field.\n\n\n\n",
    "preview": "posts/2021-08-16-aug-16/images/bren_outside.jpeg",
    "last_modified": "2021-11-01T14:28:12-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-10-a-function-i-learned/",
    "title": "Working with `ggplot`",
    "description": "Using `ggplot` with the `palmerpenguins` package",
    "author": [
      {
        "name": "Felicia Cruz",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [
      "packages"
    ],
    "contents": "\n\n\nShow code\n\nggplot(data = penguins, aes(x= flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species)) + \n  labs(title = \"Flipper Length and Body Mass by Species\",\n       subtitle = \"Palmer Penguins\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\",\n       color = \"Species\") +\n  theme_gray()\n\n\n\n\nThis scatterplot shows a positive correlation between penguin flipper length and body mass. While the Adelie and Chinstrap species are similar in size, the Gentoos weigh a lot more and have much longer flippers.\n\n\n\n",
    "preview": "posts/2021-08-10-a-function-i-learned/images/palmerpenguins.jpg",
    "last_modified": "2021-11-02T16:12:26-07:00",
    "input_file": {}
  }
]
